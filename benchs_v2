import json
import csv
from datasets import load_dataset
from collections import defaultdict
from tqdm import tqdm

# --- 1. CONFIGURA√á√ïES ---

# Arquivo JSON traduzido que voc√™ gerou com o script de tradu√ß√£o.
TRANSLATED_FILE = 'stereoset_validation_pt_nllb_formato_original_final.json'

# Nome do arquivo CSV de sa√≠da que ser√° gerado.
OUTPUT_CSV_FILE = 'amostra_avaliacao.csv'

# Quantos exemplos selecionar para cada categoria de vi√©s.
SAMPLES_PER_BIAS_TYPE = 10

# Configura√ß√µes do dataset original no Hugging Face.
DATASET_NAME = "McGill-NLP/stereoset"
CONFIGS = ['intersentence', 'intrasentence']
DATASET_SPLIT = "validation"


# --- 2. FUN√á√ÉO PRINCIPAL ---

def generate_evaluation_csv():
    """
    Fun√ß√£o principal para carregar os dados, criar os mapas de correspond√™ncia,
    selecionar as amostras e gerar o arquivo CSV.
    """
    print("üöÄ Iniciando a gera√ß√£o do arquivo CSV de amostra para avalia√ß√£o.")

    # --- Carregando o dataset traduzido (Portugu√™s) ---
    print(f"üìñ Lendo o arquivo traduzido: {TRANSLATED_FILE}")
    try:
        with open(TRANSLATED_FILE, 'r', encoding='utf-8') as f:
            translated_data = json.load(f)['data']
    except FileNotFoundError:
        print(f"‚ùå ERRO: Arquivo traduzido '{TRANSLATED_FILE}' n√£o encontrado.")
        return
    except json.JSONDecodeError as e:
        print(f"‚ùå ERRO: Falha ao ler o arquivo JSON. Erro: {e}")
        return
        
    # --- Carregando o dataset original (Ingl√™s) e criando mapas para busca r√°pida ---
    print("üìö Baixando o dataset original em Ingl√™s para compara√ß√£o...")
    en_context_map = {}  # Mapeia example_id -> contexto em ingl√™s
    en_sentence_map = {} # Mapeia sentence_id -> senten√ßa em ingl√™s

    for config in CONFIGS:
        en_dataset = load_dataset(DATASET_NAME, config, split=DATASET_SPLIT, keep_in_memory=True)
        for example in en_dataset:
            en_context_map[example['id']] = example['context']
            for sentence_obj in example['sentences']:
                en_sentence_map[sentence_obj['id']] = sentence_obj['sentence']
    
    print(f"‚úÖ {len(en_context_map)} contextos e {len(en_sentence_map)} senten√ßas em Ingl√™s foram mapeados.")

    # --- Selecionando 10 amostras de cada categoria de vi√©s ---
    print(f"üîç Selecionando {SAMPLES_PER_BIAS_TYPE} exemplos de cada categoria de vi√©s...")
    
    # Dicion√°rio para guardar as amostras: { 'bias_type': [lista_de_exemplos] }
    sampled_examples = defaultdict(list)
    
    # Lista final de linhas para o CSV
    csv_rows = []

    for task_type in ['intrasentence', 'intersentence']:
        for translated_example in tqdm(translated_data.get(task_type, []), desc=f"Processando {task_type}"):
            bias_type = translated_example['bias_type']
            
            # Adiciona o exemplo √† amostra se ainda n√£o tivermos 10 para essa categoria
            if len(sampled_examples[bias_type]) < SAMPLES_PER_BIAS_TYPE:
                sampled_examples[bias_type].append(translated_example)

    print(f"üì¶ Amostras selecionadas para as categorias: {list(sampled_examples.keys())}")

    # --- Montando as linhas do CSV com dados em Ingl√™s e Portugu√™s ---
    print("‚úçÔ∏è Montando o arquivo CSV com dados lado a lado...")
    for bias_type, examples in sampled_examples.items():
        for example in examples:
            example_id = example['id']
            task_type = 'intrasentence' if example in translated_data.get('intrasentence', []) else 'intersentence'
            
            # Busca o contexto original em ingl√™s usando o ID do exemplo
            context_en = en_context_map.get(example_id, "N/A")
            
            for sentence_obj in example['sentences']:
                sentence_id = sentence_obj['id']
                
                # Busca a senten√ßa original em ingl√™s usando o ID da senten√ßa
                sentence_en = en_sentence_map.get(sentence_id, "N/A")

                # Monta uma linha (dicion√°rio) para o CSV
                row = {
                    'task_type': task_type,
                    'bias_type': bias_type,
                    'example_id': example_id,
                    'context_en': context_en,
                    'context_pt': example['context'],
                    'sentence_id': sentence_id,
                    'sentence_en': sentence_en,
                    'sentence_pt': sentence_obj['sentence'],
                    'gold_label': sentence_obj['gold_label']
                }
                csv_rows.append(row)

    # --- Salvando o arquivo CSV ---
    if not csv_rows:
        print("‚ö†Ô∏è Nenhuma amostra foi gerada. Verifique os arquivos de entrada.")
        return

    print(f"üíæ Salvando {len(csv_rows)} linhas de amostra em '{OUTPUT_CSV_FILE}'...")
    
    # Define os cabe√ßalhos das colunas
    headers = [
        'task_type', 'bias_type', 'example_id', 
        'context_en', 'context_pt', 'sentence_id', 
        'sentence_en', 'sentence_pt', 'gold_label'
    ]

    with open(OUTPUT_CSV_FILE, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        writer.writerows(csv_rows)

    print(f"\nüéâ Arquivo '{OUTPUT_CSV_FILE}' gerado com sucesso!")


# --- 3. EXECU√á√ÉO ---

if __name__ == "__main__":
    generate_evaluation_csv()
