import json
import pandas as pd
from datasets import load_dataset, concatenate_datasets

# --- CONFIGURA√á√ïES ---
ARQUIVO_TRADUZIDO = 'stereoset_validation_pt_claude35_otimizado.json' # Seu arquivo input
ARQUIVO_SAIDA = 'verificacao_amostra_25_porcento.xlsx'                # Arquivo output
PERCENTUAL = 0.25                                                       # 25%

def gerar_dataset_verificacao():
    print("‚è≥ Carregando dataset original do HuggingFace (Ingl√™s)...")
    
    # 1. CORRE√á√ÉO DO ERRO: Carregar as duas configs separadamente e unir
    # O StereoSet no HF exige que definamos "intrasentence" ou "intersentence"
    ds_intra = load_dataset("McGill-NLP/stereoset", "intrasentence", split="validation")
    ds_inter = load_dataset("McGill-NLP/stereoset", "intersentence", split="validation")
    
    # Unimos tudo em uma lista √∫nica para facilitar a busca
    ds_full = concatenate_datasets([ds_intra, ds_inter])
    
    # Criamos um dicion√°rio para busca r√°pida por ID (Hash Map)
    # Chave: ID, Valor: O objeto completo em ingl√™s
    mapa_ingles = {item['id']: item for item in ds_full}

    print(f"‚úÖ Dataset original carregado: {len(mapa_ingles)} exemplos.")

    # 2. Carregar o arquivo traduzido (JSON)
    print(f"‚è≥ Carregando arquivo traduzido: {ARQUIVO_TRADUZIDO}...")
    try:
        with open(ARQUIVO_TRADUZIDO, 'r', encoding='utf-8') as f:
            dados_pt = json.load(f)
            # Verifica se o JSON tem a chave 'data' ou se √© uma lista direta (ajuste conforme seu JSON)
            if 'data' in dados_pt:
                dados_pt = dados_pt['data']
    except FileNotFoundError:
        print("‚ùå Erro: Arquivo JSON n√£o encontrado.")
        return

    # 3. Cruzamento de Dados (Ingl√™s vs Portugu√™s)
    lista_comparativa = []

    # Iterar pelas tarefas (intra e inter)
    for tarefa in ['intrasentence', 'intersentence']:
        if tarefa not in dados_pt: continue

        for item_pt in dados_pt[tarefa]:
            id_exemplo = item_pt['id']
            
            # Busca o original em ingl√™s
            item_en = mapa_ingles.get(id_exemplo)
            
            if not item_en:
                continue # Pula se n√£o achar o ID correspondente

            # Estrutura a linha para o Excel
            # Pegamos o contexto e as 3 frases (stereotype, anti-stereotype, unrelated)
            linha = {
                'ID': id_exemplo,
                'Tarefa': tarefa,
                'Vi√©s': item_pt['bias_type'],
                'Contexto_EN': item_en['context'],
                'Contexto_PT': item_pt['context']
            }

            # Adiciona as 3 frases comparativas
            # Nota: A ordem das sentences no JSON original e traduzido deve ser respeitada
            sentences_pt = item_pt['sentences']
            sentences_en_list = item_en['sentences']['sentence'] # HF retorna lista de strings
            
            # Seguran√ßa para caso o tamanho das listas difira (n√£o deve ocorrer)
            qtd = min(len(sentences_pt), len(sentences_en_list))
            
            for i in range(qtd):
                label = sentences_pt[i]['gold_label'] # Ex: stereotype
                linha[f'Frase_{i+1}_Label'] = label
                linha[f'Frase_{i+1}_EN'] = sentences_en_list[i]
                linha[f'Frase_{i+1}_PT'] = sentences_pt[i]['sentence']

            lista_comparativa.append(linha)

    # 4. Cria√ß√£o do DataFrame e Amostragem Estratificada
    df = pd.DataFrame(lista_comparativa)
    
    print(f"üìä Total processado: {len(df)} linhas.")
    print("üé≤ Realizando amostragem estratificada de 25%...")

    # AQUI EST√Å A L√ìGICA DE ESTRATIFICA√á√ÉO:
    # Agrupamos por Tarefa e Vi√©s para garantir representatividade de todos os grupos
    df_amostra = df.groupby(['Tarefa', 'Vi√©s'], group_keys=False).apply(
        lambda x: x.sample(frac=PERCENTUAL, random_state=42) # random_state fixa a aleatoriedade
    )

    # 5. Exportar para Excel
    print(f"üíæ Salvando {len(df_amostra)} exemplos em '{ARQUIVO_SAIDA}'...")
    
    # Ajustar largura das colunas (opcional, visual) ou apenas salvar
    df_amostra.to_excel(ARQUIVO_SAIDA, index=False)
    
    print("\n‚úÖ Conclu√≠do! Resumo da Amostra:")
    print(df_amostra.groupby(['Tarefa', 'Vi√©s']).size())

if __name__ == "__main__":
    gerar_dataset_verificacao()
