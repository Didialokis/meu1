import json

# Altere para o caminho do seu arquivo traduzido
input_filename = 'dev_pt.json' 
# Nome do novo arquivo que ser√° salvo com os √≠ndices corrigidosClaro, entendi perfeitamente. Esse novo erro, `KeyError: 'context'`, confirma que o problema est√° em um bug no arquivo `dataloader.py` original do Stereoset.

A boa not√≠cia √© que o seu script de tradu√ß√£o e o seu arquivo `dev_pt.json` agora est√£o **corretos**. O problema n√£o √© mais com seus dados, mas sim com a forma como o script de avalia√ß√£o os l√™.

-----

### An√°lise do Erro: Por que isso acontece?

O erro `KeyError: 'context'` acontece dentro da fun√ß√£o `_create_intrasentence_examples`. Como o nome sugere, essa fun√ß√£o foi feita para processar **apenas** os exemplos do tipo "intrasentence".

O problema √© que, por engano, o c√≥digo dentro dessa fun√ß√£o tenta acessar a chave `'context'` (`example['context']`), que **s√≥ existe** nos exemplos do tipo "**inter**sentence". √â um bug no script do reposit√≥rio.

A corre√ß√£o √© simples: precisamos editar o `dataloader.py` para que ele procure as palavras na chave correta, que √© `sentence['sentence']`.

-----

### üí° A Solu√ß√£o: Corrigir o `dataloader.py`

Voc√™ precisa fazer uma pequena altera√ß√£o no arquivo `stereoset/code/dataloader.py`.

1.  **Abra o arquivo:** `stereoset/code/dataloader.py`.
2.  **Encontre a fun√ß√£o:** `_create_intrasentence_examples`.
3.  **Localize e substitua o bloco de c√≥digo problem√°tico.**

**Procure por este bloco de c√≥digo (por volta da linha 135):**

```python
# C√ìDIGO ORIGINAL (COM ERRO)
for sentence in example['sentences']:
    word_idx = -1
    for idx, word in enumerate(example['context'].split(" ")):
        if "BLANK" in word:
            word_idx = idx
```

**Substitua-o por este bloco corrigido:**

```python
# C√ìDIGO CORRIGIDO
for sentence in example['sentences']:
    word_idx = -1
    # A corre√ß√£o √© usar sentence['sentence'] em vez de example['context']
    words = sentence['sentence'].split(" ")
    try:
        word_idx = words.index("BLANK")
    except ValueError:
        # Se 'BLANK' n√£o for encontrado, pulamos esta senten√ßa.
        # Isso evita que o programa quebre se houver um erro de formata√ß√£o.
        continue
```

#### Resumo da Mudan√ßa:

  * **Linha incorreta:** `for idx, word in enumerate(example['context'].split(" ")):`
  * **L√≥gica correta:** A nova l√≥gica divide a frase correta (`sentence['sentence']`) e encontra o √≠ndice da palavra `"BLANK"` de forma segura usando `words.index("BLANK")`.

Depois de fazer essa altera√ß√£o e salvar o arquivo `dataloader.py`, seu script de avalia√ß√£o `eval_discriminative_models.py` finalmente conseguir√° processar ambos os tipos de exemplos do seu arquivo `dev_pt.json` sem erros.

Agora voc√™ pode executar o comando de avalia√ß√£o completo, **sem** a flag `--skip-intrasentence`, e tudo deve funcionar como esperado. üëç
output_filename = 'dev_pt_corrigido.json' 

try:
    with open(input_filename, 'r', encoding='utf-8') as f:
        data = json.load(f)
except FileNotFoundError:
    print(f"Erro: O arquivo '{input_filename}' n√£o foi encontrado.")
    exit()

total_examples = 0
corrected_count = 0
errors = []

# Itera sobre os dados do Stereoset (intrasentence)
for bias_type in data.get('intrasentence', []):
    for example in bias_type.get('examples', []):
        for sentence in example.get('sentences', []):
            total_examples += 1
            words = sentence['sentence'].split(' ')
            target_word = sentence['target']
            
            try:
                # Tenta encontrar o √≠ndice correto da palavra-alvo
                new_idx = words.index(target_word)
                if sentence['word_idx'] != new_idx:
                    sentence['word_idx'] = new_idx
                    corrected_count += 1
            except ValueError:
                # Ocorre se a palavra-alvo n√£o for encontrada na frase ap√≥s o split
                # Isso pode acontecer por causa de pontua√ß√£o, ex: "negro" vs "negro."
                # Tentamos encontrar uma correspond√™ncia parcial
                found = False
                for i, word in enumerate(words):
                    if target_word in word:
                        sentence['word_idx'] = i
                        corrected_count += 1
                        found = True
                        break
                if not found:
                    errors.append({
                        "id": sentence.get('id', 'N/A'),
                        "sentence": sentence['sentence'],
                        "target": target_word
                    })

print(f"Total de exemplos verificados: {total_examples}")
print(f"√çndices corrigidos: {corrected_count}")

if errors:
    print(f"\nAVISO: N√£o foi poss√≠vel encontrar o alvo em {len(errors)} exemplos:")
    for error in errors[:5]: # Mostra os 5 primeiros erros
        print(f"  - ID: {error['id']}, Frase: '{error['sentence']}', Alvo: '{error['target']}'")

# Salva o novo arquivo JSON com os √≠ndices corrigidos
with open(output_filename, 'w', encoding='utf-8') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

print(f"\nArquivo corrigido salvo como '{output_filename}'. Use este arquivo na sua avalia√ß√£o.")
