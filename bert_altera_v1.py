Claro, vamos resolver isso\! O erro `KeyError` que voc√™ est√° vendo √© um sintoma cl√°ssico de um problema que aconteceu em uma etapa anterior.

A causa raiz **n√£o est√° no `evaluation.py`**. O erro est√° acontecendo porque o arquivo de previs√µes (`predictions/*.json`) foi gerado com base em dados incompletos. A corre√ß√£o que fizemos anteriormente no `dataloader.py` foi uma solu√ß√£o parcial: ela evitou o travamento (`IndexError`), mas, ao encontrar um exemplo que n√£o conseguia processar, ela simplesmente o pulou (`continue`).

Isso resultou na cria√ß√£o de "exemplos √≥rf√£os" nos dados carregados, onde um cluster de senten√ßas que deveria ter um estere√≥tipo, um anti-estere√≥tipo e um n√£o relacionado, acabou faltando uma dessas tr√™s partes. O script `evaluation.py` espera que as tr√™s estejam sempre presentes e, quando n√£o encontra, ele quebra com o `KeyError`.

A solu√ß√£o definitiva √© criar uma l√≥gica ainda mais robusta no `dataloader.py` que n√£o pule exemplos, mas que consiga encontrar a palavra-alvo mesmo quando a tradu√ß√£o altera a contagem de palavras.

-----

## A Solu√ß√£o Definitiva: Aprimorar o `dataloader.py`

Vamos substituir a l√≥gica de `set.difference` por uma abordagem baseada em listas, que √© mais resistente a tradu√ß√µes que inserem m√∫ltiplas palavras (como "programador" se tornando "engenheiro de software").

**1. Abra o arquivo `dataloader.py`**

  - V√° novamente para o arquivo `/home/sagemaker-user/stereoset/code/dataloader.py`.

**2. Localize a fun√ß√£o `__create_intrasentence_examples__`**

  - Encontre o bloco de c√≥digo que modificamos da √∫ltima vez.

**3. Substitua o Bloco Modificado pela Vers√£o Final**

  - Remova a l√≥gica anterior e a substitua por esta vers√£o mais inteligente e completa.

**C√ìDIGO A SER SUBSTITU√çDO (A L√ìGICA ANTERIOR):**

```python
# A l√≥gica que voc√™ tem agora, que usa set.difference e 'continue'
                context_words = set(example['context'].replace("BLANK", "").translate(str.maketrans('', '', string.punctuation)).split())
                # ... (resto do bloco antigo)
```

**NOVO C√ìDIGO FINAL (Substitua o bloco acima por este):**

```python
                # --- IN√çCIO DA NOVA L√ìGICA ROBUSTA ---
                # Limpa e tokeniza a frase de contexto e a frase completa
                context_tokens = [w.lower().translate(str.maketrans('', '', string.punctuation)) for w in example['context'].split()]
                sentence_tokens = [w.lower().translate(str.maketrans('', '', string.punctuation)) for w in sentence['sentence'].split()]

                # Remove o token 'BLANK' e quaisquer tokens vazios resultantes do split
                context_tokens_no_blank = [t for t in context_tokens if "blank" not in t and t]

                # A palavra-alvo √© composta por todas as palavras na senten√ßa completa que n√£o est√£o no contexto
                # Isso funciona para uma ou m√∫ltiplas palavras (ex: "cientista", "engenheiro de software")
                difference_words = [word for word in sentence_tokens if word not in context_tokens_no_blank]

                if not difference_words:
                    print(f"AVISO: Nenhuma palavra de diferen√ßa encontrada para o ID {sentence['id']}. Pulando esta senten√ßa.")
                    print(f"  Contexto: {example['context']}")
                    print(f"  Senten√ßa: {sentence['sentence']}")
                    continue

                # Junta as palavras de diferen√ßa (caso seja um termo composto)
                template_word = " ".join(difference_words)

                sentence_obj.template_word = template_word
                sentences.append(sentence_obj)
                # --- FIM DA NOVA L√ìGICA ---
```

-----

## Por que esta nova l√≥gica √© melhor? üß†

  * **Toler√¢ncia a M√∫ltiplas Palavras:** Se "programmer" (1 palavra) virou "engenheiro de software" (3 palavras), a l√≥gica de `set` falhava. A nova l√≥gica de lista captura todas as palavras extras.
  * **Mais Resiliente:** Ela compara as listas de palavras e extrai o que √© "novo", que √© exatamente o que precisamos.
  * **N√£o Corrompe os Dados:** Ao n√£o pular senten√ßas problem√°ticas (a menos que seja imposs√≠vel encontrar uma diferen√ßa), garantimos que cada exemplo tenha suas tr√™s senten√ßas, evitando o `KeyError` na etapa de avalia√ß√£o.

-----

## Pr√≥ximos Passos (Essencial\!) üéØ

Agora que o `dataloader.py` est√° corrigido de forma definitiva, voc√™ precisa refazer as etapas na ordem correta.

**1. Exclua as Previs√µes Antigas:**
Os arquivos na pasta `predictions/` foram gerados com a l√≥gica de carregamento de dados falha. Eles est√£o corrompidos.

```bash
rm -rf predictions/*
```

**2. Gere Novamente as Previs√µes:**
Execute o script `eval_discriminative_models.py` de novo. Agora ele usar√° o `dataloader.py` corrigido para carregar os dados completos e gerar previs√µes corretas.

```bash
# Exemplo para o BERTimbau
python eval_discriminative_models.py \
    --pretrained-class "neuralmind/bert-base-portuguese-cased" \
    --input-file "../data/dev_pt.json" \
    --output-file "predictions/predictions_bertimbau.json"
```

*(Execute para todos os modelos que voc√™ deseja avaliar).*

**3. Execute a Avalia√ß√£o Final:**
Agora que as previs√µes foram geradas corretamente, o script `evaluation.py` funcionar√° sem erros.

```bash
python3 evaluation.py --gold-file ../data/dev_pt.json --predictions-dir predictions/
```

Seguindo estes passos, o `KeyError` ser√° resolvido, pois o `evaluation.py` receber√° dados consistentes e completos.
