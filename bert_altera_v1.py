Claro\! O script do Stereoset √© bem projetado e, felizmente, requer uma modifica√ß√£o m√≠nima para adicionar novos modelos da biblioteca `transformers`, como o BERTimbau e o BERT multilingual.

A principal altera√ß√£o que voc√™ precisa fazer √© na lista de modelos pr√©-treinados permitidos nos argumentos da linha de comando. O restante do c√≥digo j√° √© flex√≠vel o suficiente para carregar qualquer modelo compat√≠vel com a arquitetura BERT.

-----

## Resumo da Modifica√ß√£o

Voc√™ s√≥ precisa **adicionar os nomes de identifica√ß√£o dos modelos do Hugging Face** √† lista `pretrained_model_choices` dentro da fun√ß√£o `parse_args()`.

Os identificadores s√£o:

  * **BERTimbau:** `neuralmind/bert-base-portuguese-cased`
  * **BERT Multilingual:** `bert-base-multilingual-cased`

-----

## Passo a Passo da Altera√ß√£o no C√≥digo

1.  **Localize a Fun√ß√£o `parse_args`**: Abra o arquivo `eval_discriminative_models.py` e encontre a fun√ß√£o que define os argumentos.

2.  **Edite a Lista `pretrained_model_choices`**: Adicione os dois novos modelos √† lista.

    **C√≥digo Original:**

    ```python
    def parse_args():
        """ Parses the command line arguments. """
        pretrained_model_choices = ['bert-base-uncased', 'bert-base-cased', "bert-large-uncased-whole-word-masking",
                                    'bert-large-uncased', 'bert-large-cased', 'gpt2', 'gpt2-medium', 'gpt2-large', 'roberta-base',
                                    'roberta-large', 'xlnet-base-cased', 'xlnet-large-cased']
    ```

    **C√≥digo Modificado:**

    ```python
    def parse_args():
        """ Parses the command line arguments. """
        pretrained_model_choices = ['bert-base-uncased', 'bert-base-cased', "bert-large-uncased-whole-word-masking",
                                    'bert-large-uncased', 'bert-large-cased', 'gpt2', 'gpt2-medium', 'gpt2-large', 'roberta-base',
                                    'roberta-large', 'xlnet-base-cased', 'xlnet-large-cased',
                                    'neuralmind/bert-base-portuguese-cased', # <--- ADICIONADO BERTimbau
                                    'bert-base-multilingual-cased']         # <--- ADICIONADO mBERT
    ```

**E √© isso\!** Nenhuma outra altera√ß√£o no c√≥digo √© necess√°ria. O script j√° utiliza `getattr(transformers, self.TOKENIZER).from_pretrained(self.PRETRAINED_CLASS)`, o que significa que a biblioteca `transformers` se encarregar√° de baixar e carregar o tokenizador e o modelo corretos com base no nome que voc√™ passar.

-----

## Como Executar a Avalia√ß√£o

Agora que o script aceita os novos modelos, voc√™ pode execut√°-lo a partir do seu terminal. Supondo que seu arquivo de desenvolvimento traduzido para o portugu√™s se chame `dev_pt.json` e esteja na pasta `../data/`.

### Para Avaliar o BERTimbau:

Execute o seguinte comando. Note que especificamos o nome do modelo em `--pretrained-class` e garantimos que o tokenizador e os modelos de avalia√ß√£o sejam os corretos para a arquitetura BERT.

```bash
python eval_discriminative_models.py \
    --pretrained-class "neuralmind/bert-base-portuguese-cased" \
    --tokenizer "BertTokenizer" \
    --intrasentence-model "BertLM" \
    --intersentence-model "BertNextSentence" \
    --input-file "../data/dev_pt.json" \
    --output-file "predictions_bertimbau.json"
```

### Para Avaliar o BERT Multilingual:

O comando √© quase id√™ntico, apenas mudando o nome do modelo e o arquivo de sa√≠da.

```bash
python eval_discriminative_models.py \
    --pretrained-class "bert-base-multilingual-cased" \
    --tokenizer "BertTokenizer" \
    --intrasentence-model "BertLM" \
    --intersentence-model "BertNextSentence" \
    --input-file "../data/dev_pt.json" \
    --output-file "predictions_mbert.json"
```

### üí° Pontos Importantes:

  * **`--tokenizer "BertTokenizer"`**: Tanto o BERTimbau quanto o mBERT usam a classe `BertTokenizer`.
  * **`--intrasentence-model "BertLM"`** e **`--intersentence-model "BertNextSentence"`**: Essas s√£o as classes de modelo corretas para arquiteturas baseadas em BERT no reposit√≥rio do Stereoset.
  * **`--input-file`**: Certifique-se de que o caminho para o seu arquivo `.json` traduzido esteja correto.
  * **Hardware**: A avalia√ß√£o pode ser lenta sem uma GPU. Se voc√™ n√£o tiver uma GPU dispon√≠vel, adicione a flag `--no-cuda` ao comando.
