Script de Traduﾃｧﾃ｣o Final: Recriando a Estrutura Original
Para resolver isso, nﾃ｣o podemos mais usar o conveniente mﾃｩtodo .map(). O script abaixo foi reescrito para reconstruir manualmente a estrutura original apﾃｳs a traduﾃｧﾃ｣o. Ele ﾃｩ mais detalhado, mas o resultado serﾃ｡ um arquivo JSON perfeitamente compatﾃｭvel com o dataloader.py e qualquer outra ferramenta oficial do StereoSet.

Python

# -*- coding: utf-8 -*-

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from datasets import load_dataset
import re
import json
from tqdm import tqdm

# --- 1. CONFIGURAﾃﾃ髭S ---

MODEL_NAME = "facebook/nllb-200-1.3B"
DATASET_NAME = "McGill-NLP/stereoset"
CONFIGS = ['intersentence', 'intrasentence']
DATASET_SPLIT = "validation"
SOURCE_LANG = "eng_Latn"
TARGET_LANG = "por_Latn"
BATCH_SIZE = 8

# Mapeamento para converter os labels numﾃｩricos de volta para texto
LABEL_MAP = {0: 'stereotype', 1: 'anti-stereotype', 2: 'unrelated'}

# --- 2. FUNﾃﾃ髭S AUXILIARES ---

def sanitize_text(text):
    return re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f]', '', text)


# --- 3. FUNﾃﾃグ PRINCIPAL DE TRADUﾃﾃグ ---

def traduzir_e_recriar_estrutura():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Usando dispositivo: {device}")

    print(f"Carregando o modelo '{MODEL_NAME}'...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=SOURCE_LANG)
    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)
    print("Modelo carregado com sucesso.")

    # --- ETAPA DE EXTRAﾃﾃグ ---
    # Coleta todas as sentenﾃｧas a serem traduzidas e mantﾃｩm os datasets originais
    datasets_dict = {}
    sentences_to_translate = []
    for config in CONFIGS:
        print(f"Carregando a configuraﾃｧﾃ｣o '{config}' do dataset...")
        dataset = load_dataset(DATASET_NAME, config, split=DATASET_SPLIT)
        datasets_dict[config] = dataset
        for example in dataset:
            sentences_to_translate.append(example['context'])
            for sent_obj in example['sentences']:
                sentences_to_translate.append(sent_obj['sentence'])
    
    print(f"Total de {len(sentences_to_translate)} sentenﾃｧas extraﾃｭdas para traduﾃｧﾃ｣o.")

    # --- ETAPA DE TRADUﾃﾃグ ---
    print("Iniciando a traduﾃｧﾃ｣o em lotes...")
    translated_sentences = []
    forced_bos_token_id = tokenizer.convert_tokens_to_ids(TARGET_LANG)

    for i in tqdm(range(0, len(sentences_to_translate), BATCH_SIZE), desc="Traduzindo Lotes"):
        batch = sentences_to_translate[i:i + BATCH_SIZE]
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True).to(device)
        generated_tokens = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id, max_length=128)
        batch_translated_raw = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
        batch_sanitized = [sanitize_text(text) for text in batch_translated_raw]
        translated_sentences.extend(batch_sanitized)
    print("Traduﾃｧﾃ｣o finalizada.")

    # --- ETAPA DE RECONSTRUﾃﾃグ MANUAL ---
    print("Reconstruindo o dataset na estrutura original...")
    translated_iter = iter(translated_sentences)
    
    reconstructed_data = {}
    for config in CONFIGS:
        original_dataset = datasets_dict[config]
        new_examples_list = []
        for original_example in tqdm(original_dataset, desc=f"Reconstruindo {config}"):
            new_example = {
                "id": original_example['id'],
                "bias_type": original_example['bias_type'],
                "target": original_example['target'],
                "context": next(translated_iter), # Pega o contexto traduzido
                "sentences": []
            }
            
            for original_sentence_obj in original_example['sentences']:
                new_sentence_obj = {
                    "id": original_sentence_obj['id'],
                    "sentence": next(translated_iter), # Pega a sentenﾃｧa traduzida
                    "labels": original_sentence_obj['labels'], # Mantﾃｩm os labels originais
                    "gold_label": LABEL_MAP[original_sentence_obj['gold_label']] # Converte o label numﾃｩrico para texto
                }
                new_example["sentences"].append(new_sentence_obj)
            
            new_examples_list.append(new_example)
        reconstructed_data[config] = new_examples_list

    # --- ETAPA DE SALVAMENTO ---
    final_output_structure = {
        "version": "1.1.1", # Adiciona a chave de versﾃ｣o esperada
        "data": reconstructed_data
    }
    
    output_path = f"stereoset_{DATASET_SPLIT}_pt_nllb_formato_original.json"
    print(f"Salvando o dataset final em: {output_path}")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(final_output_structure, f, ensure_ascii=False, indent=2)

    print("\n脂 Sucesso! Processo concluﾃｭdo. O arquivo estﾃ｡ 100% compatﾃｭvel com o dataloader.py.")


if __name__ == "__main__":
    traduzir_e_recriar_estrutura()

Seu Novo Fluxo de Trabalho (Simplificado e Correto)
Execute o Script de Traduﾃｧﾃ｣o (acima): Use este novo script para gerar o arquivo stereoset_validation_pt_nllb_formato_original.json. Este arquivo serﾃ｡ uma rﾃｩplica perfeita do original, apenas com os textos em portuguﾃｪs.

Use o dataloader.py: Agora, qualquer script (como o evaluation.py do repositﾃｳrio oficial) que use o dataloader.py para carregar este novo arquivo funcionarﾃ｡ sem erros.

Ajuste o Seu Script de Prediﾃｧﾃ｣o (predicao.py): Seu script de prediﾃｧﾃ｣o foi feito para a estrutura simplificada. Ele tambﾃｩm precisa de um pequeno ajuste para funcionar com a estrutura original correta.

Modificaﾃｧﾃ｣o necessﾃ｡ria no predicao.py:

Python

# No seu script predicao.py...

# ...
# Carregue os dados aninhados
with open(GOLD_FILE, 'r', encoding='utf-8') as f:
    full_data = json.load(f)
    gold_data = full_data['data'] 
# ...

# ...
# Modifique o loop principal
with tqdm(total=total_sentences, unit="sentenﾃｧa") as pbar:
    for task_type in gold_data:
        for example in gold_data[task_type]:

            # --- INﾃ垢IO DA CORREﾃﾃグ ---
            # Agora iteramos sobre a lista de dicionﾃ｡rios de sentenﾃｧas
            for sentence_obj in example['sentences']:
                sentence_id = sentence_obj['id']
                sentence_text = sentence_obj['sentence']
            # --- FIM DA CORREﾃﾃグ ---

                score = calculate_pll_score(sentence_text, model, tokenizer, device)

                predictions[task_type].append({"id": sentence_id, "score": score})
                pbar.update(1)
# ...
Com essas duas correﾃｧﾃｵes (no script de traduﾃｧﾃ｣o e no de prediﾃｧﾃ｣o), todo o seu pipeline estarﾃ｡ consistente e alinhado com a estrutura de dados oficial do StereoSet.
